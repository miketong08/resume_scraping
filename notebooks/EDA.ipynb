{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Exploratory Data Analysis\n",
    "\n",
    "## Data Preprocessing\n",
    "Now that we've scrapped all the data, we can start looking into it prior to performing some sort of analysis.\n",
    "To make things a bit more interesting, let's load the `data_large.csv` file. This file is very similar to the output from the `scraping` notebook, but it was performed over a distance of 9999 (the US is ~3000 miles across).\n",
    "We can easilly load CSV files into a `pandas.DataFrame` with the `read_csv` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large = pd.read_csv(\"./../assets/data_large.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataframe is loaded, let's check out the size (rows, columns) of the data. This is done by checking the `shape` attribute. The returned output is a tuple identifying the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38912, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_large.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38,912 entries with 5 features! Not too shabby. Let's see what a few of the entries look like. There are a few ways to do this and the common methods to use are `head()`, `tail()`, and `sample()`. Each one's first argument is the number of entries to return, by default the first two methods return 5 entires, and sample returns a single one.\n",
    "* Personally, I prefer using `sample()` for most situations. The former two are great for time series data however, or anything that has an order to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>city</th>\n",
       "      <th>searched_zipcode</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10167</th>\n",
       "      <td>10167</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>10025</td>\n",
       "      <td>https://newyork.craigslist.org/mnh/res/d/exp-h...</td>\n",
       "      <td>Experienced House Mgr. Available\\nI've worked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20974</th>\n",
       "      <td>20974</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60618</td>\n",
       "      <td>https://grandrapids.craigslist.org/res/d/exter...</td>\n",
       "      <td>Experienced Siders\\n\\nExperienced roofers\\n\\nE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20246</th>\n",
       "      <td>20246</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60618</td>\n",
       "      <td>https://chicago.craigslist.org/nwc/res/d/offic...</td>\n",
       "      <td>Experience cleaning lady is available for offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11505</th>\n",
       "      <td>11505</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>75217</td>\n",
       "      <td>https://oklahomacity.craigslist.org/res/d/no-j...</td>\n",
       "      <td>Power washing,yard cleaning, and any similar s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31793</th>\n",
       "      <td>31793</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>10029</td>\n",
       "      <td>https://newyork.craigslist.org/mnh/res/d/itali...</td>\n",
       "      <td>Dear Business Owners &amp; Financial Investors, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30736</th>\n",
       "      <td>30736</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>28269</td>\n",
       "      <td>https://charlotte.craigslist.org/res/d/indepen...</td>\n",
       "      <td>Hello, my name is Bruce, I'm a retired transpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16870</th>\n",
       "      <td>16870</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>10002</td>\n",
       "      <td>https://hudsonvalley.craigslist.org/res/d/need...</td>\n",
       "      <td>Can't afford to hire a bookkeeper full time or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24672</th>\n",
       "      <td>24672</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>95823</td>\n",
       "      <td>https://sfbay.craigslist.org/sby/res/d/class-e...</td>\n",
       "      <td>I have a Class A for 18 years, I have no point...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        city  searched_zipcode  \\\n",
       "10167       10167     NewYork             10025   \n",
       "20974       20974     Chicago             60618   \n",
       "20246       20246     Chicago             60618   \n",
       "11505       11505      Dallas             75217   \n",
       "31793       31793     NewYork             10029   \n",
       "30736       30736   Charlotte             28269   \n",
       "16870       16870     NewYork             10002   \n",
       "24672       24672  Sacramento             95823   \n",
       "\n",
       "                                                     url  \\\n",
       "10167  https://newyork.craigslist.org/mnh/res/d/exp-h...   \n",
       "20974  https://grandrapids.craigslist.org/res/d/exter...   \n",
       "20246  https://chicago.craigslist.org/nwc/res/d/offic...   \n",
       "11505  https://oklahomacity.craigslist.org/res/d/no-j...   \n",
       "31793  https://newyork.craigslist.org/mnh/res/d/itali...   \n",
       "30736  https://charlotte.craigslist.org/res/d/indepen...   \n",
       "16870  https://hudsonvalley.craigslist.org/res/d/need...   \n",
       "24672  https://sfbay.craigslist.org/sby/res/d/class-e...   \n",
       "\n",
       "                                                 content  \n",
       "10167  Experienced House Mgr. Available\\nI've worked ...  \n",
       "20974  Experienced Siders\\n\\nExperienced roofers\\n\\nE...  \n",
       "20246  Experience cleaning lady is available for offi...  \n",
       "11505  Power washing,yard cleaning, and any similar s...  \n",
       "31793  Dear Business Owners & Financial Investors, I ...  \n",
       "30736  Hello, my name is Bruce, I'm a retired transpo...  \n",
       "16870  Can't afford to hire a bookkeeper full time or...  \n",
       "24672  I have a Class A for 18 years, I have no point...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_large.sample(8)  # recall that the 8 means number of entries to return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks familiar! But what is the `Unnamed: 0` column? By default, when we export the `DataFrame` as a CSV, it saves the index number as a new column, and when it is reloaded, it does not assume that the first column is the index. There are a few ways to go about this:\n",
    "* When exporting with `DataFrame.to_csv()` use the argument `index=False` to prevent the index column being saved.\n",
    "* When importing with `pandas.read_csv()` use the argument `index_col=0` to specify that the first (or other column) is the index.\n",
    "* Drop the column after importing the CSV.\n",
    "\n",
    "Since the data is already loaded, let's use the last method of dropping the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>searched_zipcode</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6776</th>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>90044</td>\n",
       "      <td>https://orangecounty.craigslist.org/res/d/prog...</td>\n",
       "      <td>CORE COMPETENCIES\\n\\nCxO-Level Business Strate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city  searched_zipcode  \\\n",
       "6776  LosAngeles             90044   \n",
       "\n",
       "                                                    url  \\\n",
       "6776  https://orangecounty.craigslist.org/res/d/prog...   \n",
       "\n",
       "                                                content  \n",
       "6776  CORE COMPETENCIES\\n\\nCxO-Level Business Strate...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_large.drop(['Unnamed: 0'], axis=1, inplace=True)  # inplace means that it modifys the variable directly, equivilent to df_large = df_large.drop(...)\n",
    "\n",
    "df_large.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, another way to slim down the dataset is to check for duplicates. Remember how this larger set has its search distance at effectively the entire US? Well, as a result, there's a pretty good chance we're going to get duplicate entries. There's multiple ways to check for this condition:\n",
    "* Use the `DataFrame.duplicated()` method, which returns a boolean series of which rows and duplicates.\n",
    "* Use the `DataFrame.nunique()` method to figure out how many unique values there are. \n",
    "\n",
    "The issue with the first method is that it check if entries are identical. Since duplicates may exist from different zipcode searches, it may not return the duplicate's we're interested in (content or url). A simple way to check the number of duplicated values found with this approach is to `sum()` the result. This works because the return value of `duplicated()` is a boolean value per row, where False = 0 and True = 1. \n",
    "\n",
    "Let's run both methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of duplicated:  20\n",
      "\n",
      "nunique results:\n",
      " city                   18\n",
      "searched_zipcode       29\n",
      "url                 13967\n",
      "content             12933\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Sum of duplicated: ', df_large.duplicated().sum())\n",
    "print('\\nnunique results:\\n', df_large.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! As we expected, duplicated perform what we'd like. The function does accept arguments however that will allow you to perform what we're looking for (You can pass a list of columns to check, i.e. `df_large.duplicated(['content'])` which will return a boolean series). \n",
    "\n",
    "Nonetheless however!  We find that `nunique()` did what we needed, we find that there are 12,933 unique resume's. Let's actually use the `duplicated()` method here to keep just the unique resumes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataframe size:  (12933, 4)\n"
     ]
    }
   ],
   "source": [
    "df_large = df_large[~df_large.duplicated(['content'])]\n",
    "\n",
    "print(\"New dataframe size: \", df_large.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we find that the new dataframe size matches the number of unique values found in the cell above. \n",
    "\n",
    "The line above may look a little confusing, so let's break it down.\n",
    "\n",
    "1. `df_large.duplicated(['content'])` finds all the duplicated rows and by default, only keeps the first instance of it. This results in a boolean series, which denotes True/False for each entry.\n",
    "2. The tilde (\\~) denotes negation, which simply means flip all True/False values. This in effect represent's all the entries that are not duplicated. \n",
    "3. `df_large[~df_large.duplicated(['content'])]` is called indexing, which says return `df_large` where entires in the brackets are True, in this case the not duplicated rows. \n",
    "4. We reassign df_large to this new \"not duplicated\" version. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! Now the data is a little cleaner, we've reduced the size to under a third of the original!\n",
    "\n",
    "Some other useful sanity checks include: \n",
    "* `DataFrame.describe()` which displays measures of central tendency and some other metrics on all applicable columns (numerical).\n",
    "* `DataFrame.dtypes` is an attribute that keeps track of all the data types used. Useful for larger sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of you may have noticed that the URL link may not match the `City` value. This may result in issues later on. A simple fix to this is to use the url city as opposed to the only found during the search, especially since we dropped duplicates on the content feature whilst retaining only the first encountered entry.  We'll fix this with the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>searched_zipcode</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37915</th>\n",
       "      <td>phoenix</td>\n",
       "      <td>85364</td>\n",
       "      <td>https://phoenix.craigslist.org/evl/res/d/handy...</td>\n",
       "      <td>Anyone looking for help around the house or mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30132</th>\n",
       "      <td>raleigh</td>\n",
       "      <td>28269</td>\n",
       "      <td>https://raleigh.craigslist.org/res/d/affordabl...</td>\n",
       "      <td>I've been a personal private duty in-home care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30268</th>\n",
       "      <td>raleigh</td>\n",
       "      <td>28269</td>\n",
       "      <td>https://raleigh.craigslist.org/res/d/looking-f...</td>\n",
       "      <td>Hey my name is Shy 24 years old and I’m hoping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8286</th>\n",
       "      <td>hudsonvalley</td>\n",
       "      <td>10025</td>\n",
       "      <td>https://hudsonvalley.craigslist.org/res/d/seek...</td>\n",
       "      <td>28 year old male in need of employment before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>nashville</td>\n",
       "      <td>37211</td>\n",
       "      <td>https://nashville.craigslist.org/res/d/moving-...</td>\n",
       "      <td>Offering small moves, deliveries, packing , lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city  searched_zipcode  \\\n",
       "37915       phoenix             85364   \n",
       "30132       raleigh             28269   \n",
       "30268       raleigh             28269   \n",
       "8286   hudsonvalley             10025   \n",
       "21585     nashville             37211   \n",
       "\n",
       "                                                     url  \\\n",
       "37915  https://phoenix.craigslist.org/evl/res/d/handy...   \n",
       "30132  https://raleigh.craigslist.org/res/d/affordabl...   \n",
       "30268  https://raleigh.craigslist.org/res/d/looking-f...   \n",
       "8286   https://hudsonvalley.craigslist.org/res/d/seek...   \n",
       "21585  https://nashville.craigslist.org/res/d/moving-...   \n",
       "\n",
       "                                                 content  \n",
       "37915  Anyone looking for help around the house or mo...  \n",
       "30132  I've been a personal private duty in-home care...  \n",
       "30268  Hey my name is Shy 24 years old and I’m hoping...  \n",
       "8286   28 year old male in need of employment before ...  \n",
       "21585  Offering small moves, deliveries, packing , lo...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_split = df_large['url'].str.split(\"//\", expand=True)[1]\n",
    "sr_split = df_split.str.split(\".\", expand=True)[0]\n",
    "df_large['city'] = sr_split\n",
    "\n",
    "df_large.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, what the heck? Sorry, the above is not very Pythonic, but it is more efficient than looping through each row. Let's break it down.\n",
    "\n",
    "1. `pandas.Series.str.split()` acts similarly to the `split()` method on strings but is performed on an entire `pandas.Series` instead; it breaks the up the strings by the first argument. The `expand` argument makes each split a new column as opposed to a single column with a list, which is the default. \n",
    "2. Since the returned value from the split function is a `pandas.DataFrame`, the column names represent the split index (again, similar to a string split). When we split by `//`, we're removing the `https://` portion of the string, and taking the portion of the string after it by taking the 1st index.\n",
    "3. We do the same thing, but this time split at the period, and return the first split value, which is the city via url.\n",
    "4. Since we're taking a single column from the `pandas.DataFrame`, the variable will default to a series, which we can use to replace the `city` column in our original `DataFrame`.\n",
    "\n",
    "Let's see how many cities we now have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                  193\n",
       "searched_zipcode       26\n",
       "url                 12933\n",
       "content             12933\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_large.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes a lot more sense than the 18 we previously had! \n",
    "\n",
    "At this point, the `searched_zipcode` is probably useless and may actually be a bit confusing since it may not match up to the city. Let's drop it and continue our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large.drop(['searched_zipcode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Enough of this cleaning stuff, let's get to some analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a _ton_ of visulation packages available in Python (though they're not a pretty and powerful as some R ones), but by far the most commonly used is matplotlib, which is maintained by NumFOCUS. We'll be exploring some plots in both matplotlib and a higher level version based off of it called seaborn (easier to make pretty plots). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
