{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Exploratory Data Analysis\n",
    "\n",
    "## Data Preprocessing\n",
    "Now that we've scrapped all the data, we can start looking into it prior to performing some sort of analysis.\n",
    "To make things a bit more interesting, let's load the `data_large.csv` file. This file is very similar to the output from the `scraping` notebook, but it was performed over a distance of 9999 (the US is ~3000 miles across).\n",
    "We can easilly load CSV files into a `pandas.DataFrame` with the `read_csv` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large = pd.read_csv(\"./../assets/data_large.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataframe is loaded, let's check out the size (rows, columns) of the data. This is done by checking the `shape` attribute. The returned output is a tuple identifying the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38912, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_large.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38,912 entries with 5 features! Not too shabby. Let's see what a few of the entries look like. There are a few ways to do this and the common methods to use are `head()`, `tail()`, and `sample()`. Each one's first argument is the number of entries to return, by default the first two methods return 5 entires, and sample returns a single one.\n",
    "* Personally, I prefer using `sample()` for most situations. The former two are great for time series data however, or anything that has an order to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>city</th>\n",
       "      <th>searched_zipcode</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23689</th>\n",
       "      <td>23689</td>\n",
       "      <td>SanDiego</td>\n",
       "      <td>92154</td>\n",
       "      <td>https://losangeles.craigslist.org/wst/res/d/st...</td>\n",
       "      <td>I'm currently studying twice a week. I have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21862</th>\n",
       "      <td>21862</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>37211</td>\n",
       "      <td>https://memphis.craigslist.org/res/d/flooring-...</td>\n",
       "      <td>Looking for inside/outside sales position in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9517</th>\n",
       "      <td>9517</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>10025</td>\n",
       "      <td>https://newyork.craigslist.org/lgi/res/d/part-...</td>\n",
       "      <td>We are a busy Learning and Technology Center l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23534</th>\n",
       "      <td>23534</td>\n",
       "      <td>SanDiego</td>\n",
       "      <td>92154</td>\n",
       "      <td>https://losangeles.craigslist.org/wst/res/d/se...</td>\n",
       "      <td>Hi, I am 23 years old, I am a laid back guy, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10071</th>\n",
       "      <td>10071</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>10025</td>\n",
       "      <td>https://southjersey.craigslist.org/res/d/looki...</td>\n",
       "      <td>I live in hammonton and currently working in w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22623</th>\n",
       "      <td>22623</td>\n",
       "      <td>SanDiego</td>\n",
       "      <td>92154</td>\n",
       "      <td>https://losangeles.craigslist.org/sfv/res/d/lo...</td>\n",
       "      <td>Hi my names kenny im 24 years old, i was born ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18242</th>\n",
       "      <td>18242</td>\n",
       "      <td>Houston</td>\n",
       "      <td>77036</td>\n",
       "      <td>https://houston.craigslist.org/res/d/professio...</td>\n",
       "      <td>I need a professional team.\\n\\nhttps://youtu.b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>2939</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60629</td>\n",
       "      <td>https://racine.craigslist.org/res/d/interior-p...</td>\n",
       "      <td>Interior and Exterior painting. Epoxy floor co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       city  searched_zipcode  \\\n",
       "23689       23689   SanDiego             92154   \n",
       "21862       21862  Nashville             37211   \n",
       "9517         9517    NewYork             10025   \n",
       "23534       23534   SanDiego             92154   \n",
       "10071       10071    NewYork             10025   \n",
       "22623       22623   SanDiego             92154   \n",
       "18242       18242    Houston             77036   \n",
       "2939         2939    Chicago             60629   \n",
       "\n",
       "                                                     url  \\\n",
       "23689  https://losangeles.craigslist.org/wst/res/d/st...   \n",
       "21862  https://memphis.craigslist.org/res/d/flooring-...   \n",
       "9517   https://newyork.craigslist.org/lgi/res/d/part-...   \n",
       "23534  https://losangeles.craigslist.org/wst/res/d/se...   \n",
       "10071  https://southjersey.craigslist.org/res/d/looki...   \n",
       "22623  https://losangeles.craigslist.org/sfv/res/d/lo...   \n",
       "18242  https://houston.craigslist.org/res/d/professio...   \n",
       "2939   https://racine.craigslist.org/res/d/interior-p...   \n",
       "\n",
       "                                                 content  \n",
       "23689  I'm currently studying twice a week. I have a ...  \n",
       "21862  Looking for inside/outside sales position in f...  \n",
       "9517   We are a busy Learning and Technology Center l...  \n",
       "23534  Hi, I am 23 years old, I am a laid back guy, w...  \n",
       "10071  I live in hammonton and currently working in w...  \n",
       "22623  Hi my names kenny im 24 years old, i was born ...  \n",
       "18242  I need a professional team.\\n\\nhttps://youtu.b...  \n",
       "2939   Interior and Exterior painting. Epoxy floor co...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_large.sample(8)  # recall that the 8 means number of entries to return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks familiar! But what is the `Unnamed: 0` column? By default, when we export the `DataFrame` as a CSV, it saves the index number as a new column, and when it is reloaded, it does not assume that the first column is the index. There are a few ways to go about this:\n",
    "* When exporting with `DataFrame.to_csv()` use the argument `index=False` to prevent the index column being saved.\n",
    "* When importing with `pandas.read_csv()` use the argument `index_col=0` to specify that the first (or other column) is the index.\n",
    "* Drop the column after importing the CSV.\n",
    "\n",
    "Since the data is already loaded, let's use the last method of dropping the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>searched_zipcode</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>90044</td>\n",
       "      <td>https://losangeles.craigslist.org/ant/res/d/lo...</td>\n",
       "      <td>I have mig and stick experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city  searched_zipcode  \\\n",
       "6428  LosAngeles             90044   \n",
       "\n",
       "                                                    url  \\\n",
       "6428  https://losangeles.craigslist.org/ant/res/d/lo...   \n",
       "\n",
       "                              content  \n",
       "6428  I have mig and stick experience  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_large.drop(['Unnamed: 0'], axis=1, inplace=True)  # inplace means that it modifys the variable directly, equivilent to df_large = df_large.drop(...)\n",
    "\n",
    "df_large.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, another way to slim down the dataset is to check for duplicates. Remember how this larger set has its search distance at effectively the entire US? Well, as a result, there's a pretty good chance we're going to get duplicate entries. There's multiple ways to check for this condition:\n",
    "* Use the `DataFrame.duplicated()` method, which returns a boolean series of which rows and duplicates.\n",
    "* Use the `DataFrame.nunique()` method to figure out how many unique values there are. \n",
    "\n",
    "The issue with the first method is that it check if entries are identical. Since duplicates may exist from different zipcode searches, it may not return the duplicate's we're interested in (content or url). A simple way to check the number of duplicated values found with this approach is to `sum()` the result. This works because the return value of `duplicated()` is a boolean value per row, where False = 0 and True = 1. \n",
    "\n",
    "Let's run both methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of duplicated:  20\n",
      "\n",
      "nunique results:\n",
      " city                   18\n",
      "searched_zipcode       29\n",
      "url                 13967\n",
      "content             12933\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Sum of duplicated: ', df_large.duplicated().sum())\n",
    "print('\\nnunique results:\\n', df_large.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! As we expected, duplicated perform what we'd like. The function does accept arguments however that will allow you to perform what we're looking for (You can pass a list of columns to check, i.e. `df_large.duplicated(['content'])` which will return a boolean series). \n",
    "\n",
    "Nonetheless however!  We find that `nunique()` did what we needed, we find that there are 12,933 unique resume's. Let's actually use the `duplicated()` method here to keep just the unique resumes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataframe size:  (12933, 4)\n"
     ]
    }
   ],
   "source": [
    "df_large = df_large[~df_large.duplicated(['content'])]\n",
    "\n",
    "print(\"New dataframe size: \", df_large.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we find that the new dataframe size matches the number of unique values found in the cell above. \n",
    "\n",
    "The line above may look a little confusing, so let's break it down.\n",
    "\n",
    "1. `df_large.duplicated(['content'])` finds all the duplicated rows and by default, only keeps the first instance of it. This results in a boolean series, which denotes True/False for each entry.\n",
    "2. The tilde (\\~) denotes negation, which simply means flip all True/False values. This in effect represent's all the entries that are not duplicated. \n",
    "3. `df_large[~df_large.duplicated(['content'])]` is called indexing, which says return `df_large` where entires in the brackets are True, in this case the not duplicated rows. \n",
    "4. We reassign df_large to this new \"not duplicated\" version. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! Now the data is a little cleaner, we've reduced the size to under a third of the original!\n",
    "\n",
    "Some other useful sanity checks include: \n",
    "* `DataFrame.describe()` which displays measures of central tendency and some other metrics on all applicable columns (numerical).\n",
    "* `DataFrame.dtypes` is an attribute that keeps track of all the data types used. Useful for larger sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of you may have noticed that the URL link may not match the `City` value. This may result in issues later on. A simple fix to this is to use the url city as opposed to the only found during the search, especially since we dropped duplicates on the content feature whilst retaining only the first encountered entry.  We'll fix this with the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>searched_zipcode</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>killeen</td>\n",
       "      <td>77084</td>\n",
       "      <td>https://killeen.craigslist.org/res/d/honestdep...</td>\n",
       "      <td>I do not understand I am 56 a hard worker look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td>modesto</td>\n",
       "      <td>93722</td>\n",
       "      <td>https://modesto.craigslist.org/res/d/experienc...</td>\n",
       "      <td>I am a freelance editor/proofreader located in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8078</th>\n",
       "      <td>newyork</td>\n",
       "      <td>10025</td>\n",
       "      <td>https://newyork.craigslist.org/wch/res/d/hirin...</td>\n",
       "      <td>Would you like to work with a friendly and res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>southjersey</td>\n",
       "      <td>10025</td>\n",
       "      <td>https://southjersey.craigslist.org/res/d/perso...</td>\n",
       "      <td>Willing to work weekends\\nFlexible during the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>sanantonio</td>\n",
       "      <td>77084</td>\n",
       "      <td>https://sanantonio.craigslist.org/res/d/lookin...</td>\n",
       "      <td>Im a very responsible and honest young man tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              city  searched_zipcode  \\\n",
       "4537       killeen             77084   \n",
       "19893      modesto             93722   \n",
       "8078       newyork             10025   \n",
       "10294  southjersey             10025   \n",
       "4375    sanantonio             77084   \n",
       "\n",
       "                                                     url  \\\n",
       "4537   https://killeen.craigslist.org/res/d/honestdep...   \n",
       "19893  https://modesto.craigslist.org/res/d/experienc...   \n",
       "8078   https://newyork.craigslist.org/wch/res/d/hirin...   \n",
       "10294  https://southjersey.craigslist.org/res/d/perso...   \n",
       "4375   https://sanantonio.craigslist.org/res/d/lookin...   \n",
       "\n",
       "                                                 content  \n",
       "4537   I do not understand I am 56 a hard worker look...  \n",
       "19893  I am a freelance editor/proofreader located in...  \n",
       "8078   Would you like to work with a friendly and res...  \n",
       "10294  Willing to work weekends\\nFlexible during the ...  \n",
       "4375   Im a very responsible and honest young man tha...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_split = df_large['url'].str.split(\"//\", expand=True)[1]\n",
    "sr_split = sr_split.str.split(\".\", expand=True)[0]\n",
    "df_large['city'] = sr_split\n",
    "\n",
    "df_large.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, what the heck? Sorry, the above is not very Pythonic, but it is more efficient than looping through each row. Let's break it down.\n",
    "\n",
    "1. `pandas.Series.str.split()` acts similarly to the `split()` method on strings but is performed on an entire `pandas.Series` instead; it breaks the up the strings by the first argument. The `expand` argument makes each split a new column as opposed to a single column with a list, which is the default. \n",
    "2. Since the returned value from the split function is a `pandas.DataFrame`, the column names represent the split index (again, similar to a string split). When we split by `//`, we're removing the `https://` portion of the string, and taking the portion of the string after it by taking the 1st index.\n",
    "3. We do the same thing, but this time split at the period, and return the first split value, which is the city via url.\n",
    "4. Since we're taking a single column from the `pandas.DataFrame`, the variable will default to a series, which we can use to replace the `city` column in our original `DataFrame`.\n",
    "\n",
    "Let's see how many cities we now have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                  193\n",
       "searched_zipcode       26\n",
       "url                 12933\n",
       "content             12933\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_large.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes a lot more sense than the 18 we previously had! \n",
    "\n",
    "At this point, the `searched_zipcode` is probably useless and may actually be a bit confusing since it may not match up to the city. Let's drop it and continue our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large.drop(['searched_zipcode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_education(driver, url):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        paths = driver.find_elements_by_xpath('/html/body/section/section/section/div[1]/p/span')\n",
    "        education = [i.text for i in paths if i.text.find('education') != -1]  # sometimes the last item is a liscense\n",
    "        if len(education) == 0:\n",
    "            return education[0].split(':')[-1].strip()\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome(\"./../assets/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in df_large.iterrows():\n",
    "    df_large.loc[i, 'education'] = get_education(driver, v['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Enough of this cleaning stuff, let's get to some analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a _ton_ of visulation packages available in Python (though they're not a pretty and powerful as some R ones), but by far the most commonly used is matplotlib, which is maintained by NumFOCUS. We'll be exploring some plots in both matplotlib and a higher level version based off of it called seaborn (easier to make pretty plots). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
