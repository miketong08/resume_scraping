{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping and processing resumes off Craigslist\n",
    "\n",
    "To gather summary statistics, you'll probably first want to figure out where the most populated areas are. There is a few ways to go about this, but to make searches easier on Craigslist, zip codes make life a lot easier, and we can define a radius around that zip code. The 100 most populated zip codes was found via http://localistica.com/usa/zipcodes/most-populated-zipcodes/.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Video  # Jupyter notebook methods\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./../scripts/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expalain what a webdriver is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"./../assets/chromedriver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make our first automated move to Craigslist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://craigslist.org\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it unfortunately looks like Craigslist defaults to searching in your local area. You could manually change the location by searching for a new one... or is there an automated way of doing this? \n",
    "\n",
    "Let's see what happens when you search for a new address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"1000\" height=\"600\" autoplay controls>\n",
       "  <source src=\"./../assets/videos/craigslist_hyperlink_zip.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"1000\" height=\"600\" autoplay controls>\n",
    "  <source src=\"./../assets/videos/craigslist_hyperlink_zip.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's subtle, but the hyperlink provides a lot of information. Searching CL in different cities can be done by changing following the format of ```{cityname}.craigslist.org/?search_distance={distance}&postal={zipcode}```. \n",
    "\n",
    "With this knowledge we are now able to change the area that we are searching! So what now? Do we compile a list of every city and their zipcode? Naw, we're smarter than that. There are various approaches to this, such as simply changing the distance to something really large (9999) and pick the middle of America, but a more clever approach may be to find the cities and zipcodes with the highest populations. For learning purposes, let's give the latter a shot!\n",
    "\n",
    "First we're going to find a website that provides a list of the most populated zipcodes, the Google's tells us that http://localistica.com/usa/zipcodes/most-populated-zipcodes/ provides just that information. Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://localistica.com/usa/zipcodes/most-populated-zipcodes/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool site! There's also a really convenient table that provides both the zip code and city! But how do we get this table into our Notebook? Yes we can copy and paste, or even worse, manually copy down the values. But here's where selenium shines! We can quickly copy the table into our notebook by extracting the HTML element. This can be done in a few ways but we're going to do this through the `XPath` on the page (this of this as the path to some element, i.e. the table). The video below shows how to get the `XPath` of a webpage element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"1000\" height=\"600\" autoplay controls>\n",
       "  <source src=\"./../assets/videos/getting_xpaths.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"1000\" height=\"600\" autoplay controls>\n",
    "  <source src=\"./../assets/videos/getting_xpaths.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `XPath` copied, we can get the element by telling the driver to `find_element_by_xpath`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage_table = driver.find_element_by_xpath('//*[@id=\"frmAF\"]/div[6]/div/div[1]/div[2]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is returned is a `WebElement` class. It has a few methods and attributes but what we're interested in is the `text` attribute, which contains the raw information. Let's see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webpage_table type:  <class 'selenium.webdriver.remote.webelement.WebElement'>\n",
      "webpage_table text: \n",
      " ZipCode City Population Growth Age Income per household\n",
      "79936 El Paso TX 115,556 3% 31.00 $42,857.00\n",
      "90011 Los Angeles CA 106,326 2% 26.20 $23,851.00\n",
      "60629 Chicago IL 105,209 -8% 28.80 $40,279.00\n",
      "90650 Norwalk CA 104,765 0% 32.50 $46,012.00\n",
      "90201 Bell Gardens CA 101,479 0% 27.80 $30,029.00\n",
      "77084 Houston TX 101,233 6% 31.20 $53,075.00\n",
      "92335 Fontana CA 99,743 4% 26.90 $35,008.00\n",
      "78521 Brownsville TX 99,632 5% 28.00 $23,426.00\n",
      "77449 Katy TX 99,586 5% 29.60 $59,198.00\n",
      "78572 Mission TX 96,822 22% 31.50 $23,799.00\n",
      "90250 Hawthorne CA 96,593 3% 31.90 $33,656.00\n",
      "90280 South Gate CA 95,430 1% 29.40 $35,744.00\n",
      "11226 Brooklyn NY 94,814 -7% 34.50 $29,498.00\n",
      "90805 Long Beach CA 94,475 1% 29.00 $32,565.00\n",
      "91331 Pacoima CA 93,821 -10% 29.50 $39,225.00\n",
      "08701 Lakewood NJ 93,320 0% 23.90 $35,647.00\n",
      "90044 Los Angeles CA 92,967 3% 28.60 $22,091.00\n",
      "92336 Fontana CA 92,195 4% 30.10 $55,340.00\n",
      "00926 San Juan PR 91,579 -18% 39.10 $26,306.00\n",
      "94565 Pittsburg CA 90,935 6% 31.80 $48,523.00\n",
      "10467 Bronx NY 90,492 -7% 32.80 $29,044.00\n",
      "92683 Westminster CA 89,851 0% 38.70 $49,686.00\n",
      "75052 Grand Prairie TX 89,829 0% 32.30 $60,254.00\n",
      "91342 Sylmar CA 89,725 -2% 31.90 $48,744.00\n",
      "92704 Santa Ana CA 89,527 1% 29.80 $49,923.00\n",
      "30044 Lawrenceville GA 87,610 9% 32.00 $60,427.00\n",
      "10025 New York NY 86,082 -9% 39.50 $49,733.00\n",
      "92503 Riverside CA 85,990 1% 30.80 $44,829.00\n",
      "92804 Anaheim CA 85,970 0% 33.00 $41,887.00\n",
      "78577 Pharr TX 85,926 17% 28.00 $24,216.00\n",
      "75217 Dallas TX 84,944 5% 27.10 $31,532.00\n",
      "92376 Rialto CA 84,462 3% 27.60 $37,568.00\n",
      "93307 Bakersfield CA 84,172 1% 25.60 $26,462.00\n",
      "10456 Bronx NY 84,128 -2% 29.80 $16,664.00\n",
      "10002 New York NY 84,099 3% 39.70 $24,022.00\n",
      "91911 Chula Vista CA 83,259 0% 33.50 $38,010.00\n",
      "91744 La Puente CA 82,850 -2% 30.90 $46,792.00\n",
      "75070 Mckinney TX 82,329 9% 33.90 $84,847.00\n",
      "77036 Houston TX 82,059 12% 29.50 $26,931.00\n",
      "93722 Fresno CA 81,972 6% 29.50 $43,256.00\n",
      "92345 Hesperia CA 81,522 3% 31.20 $41,423.00\n",
      "60618 Chicago IL 81,196 -13% 32.50 $41,355.00\n",
      "93033 Oxnard CA 81,183 -1% 27.80 $46,342.00\n",
      "93550 Palmdale CA 80,635 7% 27.50 $37,484.00\n",
      "95076 Watsonville CA 80,408 -2% 31.10 $45,354.00\n",
      "11230 Brooklyn NY 80,243 -7% 33.90 $32,327.00\n",
      "11368 Corona NY 79,999 -37% 30.80 $34,746.00\n",
      "37013 Antioch TN 79,687 1% 30.80 $46,063.00\n",
      "11373 Elmhurst NY 79,681 -26% 35.30 $38,151.00\n",
      "79912 El Paso TX 79,333 2% 35.00 $48,627.00\n",
      "37211 Nashville TN 79,153 5% 31.20 $37,141.00\n",
      "30043 Lawrenceville GA 78,946 -1% 34.30 $71,424.00\n",
      "11206 Brooklyn NY 78,610 -3% 28.50 $18,661.00\n",
      "10453 Bronx NY 78,009 0% 29.70 $21,109.00\n",
      "92154 San Diego CA 77,614 -2% 32.90 $42,970.00\n",
      "11355 Flushing NY 77,581 -10% 40.50 $36,973.00\n",
      "95823 Sacramento CA 77,463 4% 29.10 $36,001.00\n",
      "77479 Sugar Land TX 77,169 3% 39.00 $96,118.00\n",
      "91706 Baldwin Park CA 76,873 0% 30.50 $41,621.00\n",
      "10458 Bronx NY 76,836 -3% 28.40 $22,072.00\n",
      "92553 Moreno Valley CA 76,811 4% 26.80 $38,554.00\n",
      "90706 Bellflower CA 76,519 0% 31.90 $39,362.00\n",
      "23464 Virginia Beach VA 76,485 5% 36.00 $53,486.00\n",
      "11212 Brooklyn NY 76,440 -10% 31.90 $20,839.00\n",
      "60617 Chicago IL 76,284 -10% 35.40 $35,534.00\n",
      "91709 Chino Hills CA 76,274 1% 36.60 $78,336.00\n",
      "11214 Brooklyn NY 76,206 -16% 38.90 $33,765.00\n",
      "11219 Brooklyn NY 76,158 -21% 27.20 $26,648.00\n",
      "91910 Chula Vista CA 76,052 0% 35.60 $42,970.00\n",
      "22193 Woodbridge VA 76,025 3% 32.60 $67,190.00\n",
      "77429 Cypress TX 76,016 4% 34.80 $78,527.00\n",
      "93535 Lancaster CA 75,841 5% 28.30 $39,747.00\n",
      "66062 Olathe KS 75,688 1% 32.80 $68,682.00\n",
      "93257 Porterville CA 75,659 0% 29.10 $30,995.00\n",
      "30349 Atlanta GA 75,615 10% 31.40 $39,141.00\n",
      "60647 Chicago IL 75,516 -15% 30.70 $35,283.00\n",
      "77584 Pearland TX 75,508 6% 33.60 $70,113.00\n",
      "10452 Bronx NY 75,321 0% 30.20 $20,606.00\n",
      "77573 League City TX 75,290 4% 34.90 $68,458.00\n",
      "11377 Woodside NY 75,274 -19% 35.70 $37,360.00\n",
      "11207 Brooklyn NY 75,149 -24% 31.00 $24,163.00\n",
      "77494 Katy TX 75,051 17% 33.70 $86,488.00\n",
      "75211 Dallas TX 74,937 2% 27.10 $32,702.00\n",
      "11234 Brooklyn NY 74,872 -17% 39.10 $51,446.00\n",
      "28269 Charlotte NC 74,794 5% 32.60 $61,899.00\n",
      "11235 Brooklyn NY 74,770 -5% 45.00 $31,013.00\n",
      "94544 Hayward CA 74,736 2% 32.30 $49,452.00\n",
      "10029 New York NY 74,350 -2% 33.30 $22,232.00\n",
      "60625 Chicago IL 74,239 -5% 32.50 $40,083.00\n",
      "89110 Las Vegas NV 74,141 4% 30.10 $43,073.00\n",
      "92509 Riverside CA 74,036 -1% 29.90 $45,995.00\n",
      "77083 Houston TX 73,953 4% 32.00 $52,931.00\n",
      "91335 Reseda CA 73,881 0% 35.50 $40,792.00\n",
      "85364 Yuma AZ 73,806 -1% 31.10 $31,515.00\n",
      "87121 Albuquerque NM 73,554 -4% 27.90 $34,359.00\n",
      "10468 Bronx NY 73,501 -3% 31.30 $26,852.00\n",
      "90255 Huntington Park CA 73,477 -2% 29.10 $30,375.00\n",
      "93065 Simi Valley CA 73,357 1% 37.10 $72,384.00\n",
      "91710 Chino CA 73,117 -9% 33.00 $55,185.00\n",
      "10462 Bronx NY 73,071 -3% 34.90 $33,735.00\n"
     ]
    }
   ],
   "source": [
    "print(\"webpage_table type: \", type(webpage_table))\n",
    "print(\"webpage_table text: \\n\", webpage_table.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyy! We got the table! Now we need to get just the zipcodes and cities. This processes is often referred to as _parsing_. Separating the zipcodes and city names is actually not entirely intuitive, nor is it important for this tutorial. We provided a simple helper function that does this from the `ancillary` library as `parse_webpage_table`. Feel free to view that code, or don't and just think of it as a magical black box.\n",
    "\n",
    "The function returns a list of tuples containing ({city}, {zipcode}). Let's see the first few. Note that the spaces in the city names is removed because that's how craigslist processes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ancillary import parse_webpage_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage_table_info = parse_webpage_table(webpage_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ElPaso', '79936'),\n",
       " ('LosAngeles', '90011'),\n",
       " ('Chicago', '60629'),\n",
       " ('Norwalk', '90650'),\n",
       " ('BellGardens', '90201')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage_table_info[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! For a sanity check, let's make sure that all 100 rows are captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements parsed table:  100\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of elements parsed table: \", len(webpage_table_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet, now that we're able to search different cities, let's check out resumes! Back to Craigslist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://craigslist.org\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we search a new city and click on ```resumes``` you'll notice that the hyperlink adds a bit more information, in the format of, `https://{city}.craigslist.org/d/resumes/search/rrr?postal={zip}&search_distance={distance}`. This is perfect since we have all the information we need! \n",
    "\n",
    "Let's try this out with one of the cities and zipcodes we found to be heavily populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "city, zipcode = webpage_table_info[0]\n",
    "distance = 30\n",
    "\n",
    "driver.get(\"https://{}.craigslist.org/d/resumes/search/rrr?postal={}&search_distance={}\".format(city, zipcode, distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can now start scraping these resume's across all the cities! \n",
    "\n",
    "First we need to get all the hyperlinks associated with the posts, this can be done in the DevTool panel once again (F12). Search through a line highlights the table in the CL page, and copy that `XPath` again. See below for the example, the `XPath` should be `//*[@id=\"sortable-results\"]/ul`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./../assets/images/cl_table_ref.png\" \n",
       "    alt=\"DevTool example for location of CL table element \" \n",
       "    style=\"width:1000px;height:600px;\"\n",
       ">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img src=\"./../assets/images/cl_table_ref.png\" \n",
    "    alt=\"DevTool example for location of CL table element \" \n",
    "    style=\"width:1000px;height:600px;\"\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_results = driver.find_element_by_xpath('//*[@id=\"sortable-results\"]/ul')\n",
    "cl_results_items = cl_results.find_elements_by_tag_name(\"li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://elpaso.craigslist.org/res/d/professional-talented-and-energetic/6966671942.html\n"
     ]
    }
   ],
   "source": [
    "item = cl_results_items[0]\n",
    "url = item.find_element_by_tag_name('a').get_attribute('href')\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boom, we're able to pull URLs! We can now simple go through all the URLs we find and pull the information through selenium once again. \n",
    "\n",
    "Let's start with pulling resume information from the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we find the `XPath`, this time for the content body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = driver.find_element_by_xpath('//*[@id=\"postingbody\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliable well organized professional with strong leadership qualities. Committed to producing results above and beyond what is expected. Strong in conflict resolutions. Your company will love to have an enthusiastic, discipline, knowledgeable & fast learner employee like me. Available IMMEDIATELY. Full-time job offer desirable.\n",
      "\n",
      "My career expertise areas are:\n",
      "• Customer Service\n",
      "• Customer Satisfaction\n",
      "• Salesperson\n",
      "• Administrative Assistant\n",
      "• Human Resources Assistant\n",
      "• Human Resources Specialist\n",
      "• Shift Supervisor\n",
      "• Management\n",
      "• Law Enforcement/Security Specialist\n",
      "\n",
      "I believe that I would be an assets to your company because my relevant knowledge, skills and abilities for this job includes:\n",
      "\n",
      "1. Bilingual Spanish & English\n",
      "2. Clerical Skills\n",
      "3. Microsoft Office Suite\n",
      "4. High Stress Environment\n",
      "5. High degree of initiative\n",
      "6. Proven Leadership\n",
      "7. Integrity\n",
      "8. Problem Solving\n",
      "9. High Degree of Initiative\n",
      "\n",
      "Over 15 years career in law enforcement with a successfully approved MBA in Human Resources.\n"
     ]
    }
   ],
   "source": [
    "print(content.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
